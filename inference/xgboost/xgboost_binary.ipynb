{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## dataset creation"
      ],
      "metadata": {
        "id": "ngtakP4G58W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def combine_csv_files(input_files, output_file):\n",
        "    \"\"\"\n",
        "    Combine multiple CSV files into a single output file.\n",
        "\n",
        "    Args:\n",
        "        input_files (list): List of input CSV file paths\n",
        "        output_file (str): Output file path\n",
        "    \"\"\"\n",
        "    # Create an empty list to store dataframes\n",
        "    dfs = []\n",
        "\n",
        "    # Read each input file and append to the list\n",
        "    for file_path in input_files:\n",
        "        print(f\"Reading {file_path}...\")\n",
        "        try:\n",
        "            # Using tab as separator based on the sample data\n",
        "            df = pd.read_csv(file_path, sep='\\t')\n",
        "            print(f\"  Found {len(df)} rows and {len(df.columns)} columns\")\n",
        "            dfs.append(df)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {file_path}: {e}\")\n",
        "\n",
        "    # Concatenate all dataframes\n",
        "    if dfs:\n",
        "        combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "        # Write to output file\n",
        "        print(f\"Writing {len(combined_df)} rows to {output_file}...\")\n",
        "        combined_df.to_csv(output_file, index=False, sep='\\t')\n",
        "        print(\"Done!\")\n",
        "        return combined_df\n",
        "    else:\n",
        "        print(\"No data to combine!\")\n",
        "        return None\n",
        "\n",
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Input files\n",
        "    input_files = [\"monday.csv\",\"tuesday.csv\",\"wednesday.csv\"]\n",
        "\n",
        "    # Check if files exist\n",
        "    for file in input_files:\n",
        "        if not os.path.exists(file):\n",
        "            print(f\"Warning: {file} does not exist in the current directory\")\n",
        "\n",
        "    # Output file\n",
        "    output_file = \"train_dataset_b.csv\"\n",
        "\n",
        "    # Combine files\n",
        "    combined_data = combine_csv_files(input_files, output_file)\n",
        "\n",
        "    # Print summary\n",
        "    if combined_data is not None:\n",
        "        print(\"\\nSummary:\")\n",
        "        print(f\"Total rows in combined file: {len(combined_data)}\")\n",
        "        print(f\"Columns: {', '.join(combined_data.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDzSkF2a58Uz",
        "outputId": "96c3a04c-6b61-45ea-874c-2393a0aaa58e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading monday.csv...\n",
            "  Found 371624 rows and 1 columns\n",
            "Reading tuesday.csv...\n",
            "  Found 322078 rows and 1 columns\n",
            "Reading wednesday.csv...\n",
            "  Found 496641 rows and 1 columns\n",
            "Writing 1190343 rows to train_dataset_b.csv...\n",
            "Done!\n",
            "\n",
            "Summary:\n",
            "Total rows in combined file: 1190343\n",
            "Columns: id,Flow ID,Src IP,Src Port,Dst IP,Dst Port,Protocol,Timestamp,Flow Duration,Total Fwd Packet,Total Bwd packets,Total Length of Fwd Packet,Total Length of Bwd Packet,Fwd Packet Length Max,Fwd Packet Length Min,Fwd Packet Length Mean,Fwd Packet Length Std,Bwd Packet Length Max,Bwd Packet Length Min,Bwd Packet Length Mean,Bwd Packet Length Std,Flow Bytes/s,Flow Packets/s,Flow IAT Mean,Flow IAT Std,Flow IAT Max,Flow IAT Min,Fwd IAT Total,Fwd IAT Mean,Fwd IAT Std,Fwd IAT Max,Fwd IAT Min,Bwd IAT Total,Bwd IAT Mean,Bwd IAT Std,Bwd IAT Max,Bwd IAT Min,Fwd PSH Flags,Bwd PSH Flags,Fwd URG Flags,Bwd URG Flags,Fwd RST Flags,Bwd RST Flags,Fwd Header Length,Bwd Header Length,Fwd Packets/s,Bwd Packets/s,Packet Length Min,Packet Length Max,Packet Length Mean,Packet Length Std,Packet Length Variance,FIN Flag Count,SYN Flag Count,RST Flag Count,PSH Flag Count,ACK Flag Count,URG Flag Count,CWR Flag Count,ECE Flag Count,Down/Up Ratio,Average Packet Size,Fwd Segment Size Avg,Bwd Segment Size Avg,Fwd Bytes/Bulk Avg,Fwd Packet/Bulk Avg,Fwd Bulk Rate Avg,Bwd Bytes/Bulk Avg,Bwd Packet/Bulk Avg,Bwd Bulk Rate Avg,Subflow Fwd Packets,Subflow Fwd Bytes,Subflow Bwd Packets,Subflow Bwd Bytes,FWD Init Win Bytes,Bwd Init Win Bytes,Fwd Act Data Pkts,Fwd Seg Size Min,Active Mean,Active Std,Active Max,Active Min,Idle Mean,Idle Std,Idle Max,Idle Min,ICMP Code,ICMP Type,Total TCP Flow Time,Label,Attempted Category\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "def split_csv_file(input_file, train_output, test_output, test_size=0.3, random_state=42):\n",
        "    \"\"\"\n",
        "    Split a CSV file into training and testing sets.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to the input CSV file\n",
        "        train_output (str): Path to save the training set\n",
        "        test_output (str): Path to save the testing set\n",
        "        test_size (float): Proportion of data to include in the test set (default: 0.3)\n",
        "        random_state (int): Random seed for reproducibility\n",
        "    \"\"\"\n",
        "    print(f\"Loading data from {input_file}...\")\n",
        "\n",
        "    try:\n",
        "        # Try to read the CSV file with tab delimiter\n",
        "        df = pd.read_csv(input_file, sep=',')\n",
        "\n",
        "        # If there's only one column and it contains commas, the file might be using a different delimiter\n",
        "        if len(df.columns) == 1 and ',' in str(df.iloc[0, 0]):\n",
        "            print(\"Detected possible comma-separated values in a tab-delimited file...\")\n",
        "            # Try reading with comma delimiter\n",
        "            df = pd.read_csv(input_file, sep=',')\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading with standard delimiters: {e}\")\n",
        "        print(\"Trying to read with custom parsing...\")\n",
        "\n",
        "        # Read the file as text and parse manually\n",
        "        with open(input_file, 'r', encoding='utf-8') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        # Find the delimiter by inspecting the first line\n",
        "        first_line = lines[0].strip()\n",
        "        if '\\t' in first_line:\n",
        "            delimiter = '\\t'\n",
        "        elif ',' in first_line:\n",
        "            delimiter = ','\n",
        "        else:\n",
        "            print(\"Could not determine delimiter. Defaulting to comma.\")\n",
        "            delimiter = ','\n",
        "\n",
        "        # Parse the header\n",
        "        header = lines[0].strip().split(delimiter)\n",
        "\n",
        "        # Parse the data\n",
        "        data = []\n",
        "        for line in lines[1:]:\n",
        "            if line.strip():  # Skip empty lines\n",
        "                values = line.strip().split(delimiter)\n",
        "                if len(values) == len(header):  # Only add rows with correct number of columns\n",
        "                    data.append(values)\n",
        "                else:\n",
        "                    print(f\"Skipping row with {len(values)} values (header has {len(header)} columns)\")\n",
        "\n",
        "        # Create DataFrame\n",
        "        df = pd.DataFrame(data, columns=header)\n",
        "\n",
        "    print(f\"Dataset loaded with shape: {df.shape}\")\n",
        "\n",
        "    # Split the data\n",
        "    print(f\"Splitting data into {100-test_size*100}% training and {test_size*100}% testing...\")\n",
        "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    print(f\"Training set shape: {train_df.shape}\")\n",
        "    print(f\"Testing set shape: {test_df.shape}\")\n",
        "\n",
        "    # Save the split datasets\n",
        "    print(f\"Saving training set to {train_output}...\")\n",
        "    train_df.to_csv(train_output, index=False, sep='\\t')\n",
        "\n",
        "    print(f\"Saving testing set to {test_output}...\")\n",
        "    test_df.to_csv(test_output, index=False, sep='\\t')\n",
        "\n",
        "    # Create download links\n",
        "    print(\"Creating download links for the files...\")\n",
        "    files.download(train_output)\n",
        "    files.download(test_output)\n",
        "\n",
        "    print(\"Files saved and download links created!\")\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    # Set file paths\n",
        "    input_file = \"combined_data.csv\"  # File already in Colab\n",
        "    train_output = \"train_data.csv\"\n",
        "    test_output = \"test_data.csv\"\n",
        "\n",
        "    # Check if the input file exists\n",
        "    if not os.path.exists(input_file):\n",
        "        print(f\"Error: File '{input_file}' not found in the current directory.\")\n",
        "        print(\"Current directory contains these files:\")\n",
        "        print(os.listdir())\n",
        "        return\n",
        "\n",
        "    # Split the data\n",
        "    split_csv_file(input_file, train_output, test_output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "zeM2eVaC58SO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "9c930ea6-6599-4b1a-8e98-41c26efb78a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data from combined_data.csv...\n",
            "Dataset loaded with shape: (2099976, 91)\n",
            "Splitting data into 70.0% training and 30.0% testing...\n",
            "Training set shape: (1469983, 91)\n",
            "Testing set shape: (629993, 91)\n",
            "Saving training set to train_data.csv...\n",
            "Saving testing set to test_data.csv...\n",
            "Creating download links for the files...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_040787a0-1c3b-4f7a-b5b6-b3163495c420\", \"train_data.csv\", 806270772)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_481339cc-ab90-40ed-b0db-6601b56945c2\", \"test_data.csv\", 345708431)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files saved and download links created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "def get_delimiter(file_path: str) -> str:\n",
        "    with open(file_path, 'r') as csvfile:\n",
        "        delimiter = str(csv.Sniffer().sniff(csvfile.read()).delimiter)\n",
        "        return delimiter\n",
        "\n",
        "print(get_delimiter(\"monday.csv\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_J53Vf6dsuh",
        "outputId": "95cec60d-acf0-4aa0-9ff6-b5003493b227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TSXsruLwZPzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qk-KdaAwZPw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sMG17R8rZPuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2zRW4LI-ZPrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oB_9bKuiZPkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def enhance_training_data(train_file, test_file, output_file, k_samples=1000, random_seed=42):\n",
        "    \"\"\"\n",
        "    Enhance training dataset by including K random samples from the test dataset.\n",
        "\n",
        "    Args:\n",
        "        train_file (str): Path to the training CSV file (e.g., combined Mon-Wed)\n",
        "        test_file (str): Path to the test CSV file (e.g., combined Thu-Fri)\n",
        "        output_file (str): Path to save the enhanced training dataset\n",
        "        k_samples (int): Number of random samples to include from test dataset\n",
        "        random_seed (int): Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The enhanced training dataset\n",
        "    \"\"\"\n",
        "    print(f\"Enhancing training data with {k_samples} samples from test data...\")\n",
        "\n",
        "    # Check if files exist\n",
        "    for file in [train_file, test_file]:\n",
        "        if not os.path.exists(file):\n",
        "            raise FileNotFoundError(f\"File not found: {file}\")\n",
        "\n",
        "    # Read the datasets\n",
        "    try:\n",
        "        print(f\"Reading training file: {train_file}\")\n",
        "        train_df = pd.read_csv(train_file, sep='\\t')\n",
        "        print(f\"  Training data: {len(train_df)} rows, {len(train_df.columns)} columns\")\n",
        "\n",
        "        print(f\"Reading test file: {test_file}\")\n",
        "        test_df = pd.read_csv(test_file, sep='\\t')\n",
        "        print(f\"  Test data: {len(test_df)} rows, {len(test_df.columns)} columns\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading files: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Validate column consistency\n",
        "    if set(train_df.columns) != set(test_df.columns):\n",
        "        print(\"Warning: Column mismatch between training and test datasets\")\n",
        "        print(f\"  Training columns: {train_df.columns.tolist()}\")\n",
        "        print(f\"  Test columns: {test_df.columns.tolist()}\")\n",
        "        print(\"  Proceeding with intersection of columns...\")\n",
        "        common_columns = list(set(train_df.columns).intersection(set(test_df.columns)))\n",
        "        train_df = train_df[common_columns]\n",
        "        test_df = test_df[common_columns]\n",
        "\n",
        "    # Sample from test dataset\n",
        "    np.random.seed(random_seed)\n",
        "    sample_size = min(k_samples, len(test_df))\n",
        "\n",
        "    if sample_size < k_samples:\n",
        "        print(f\"Warning: Requested {k_samples} samples, but test dataset only has {len(test_df)} rows\")\n",
        "        print(f\"  Using {sample_size} samples instead\")\n",
        "\n",
        "    # Take stratified sample if 'Label' column exists\n",
        "    if 'Label' in test_df.columns:\n",
        "        print(\"Taking stratified sample based on 'Label' column...\")\n",
        "        # Get the class distribution\n",
        "        label_counts = test_df['Label'].value_counts(normalize=True)\n",
        "\n",
        "        # Initialize an empty DataFrame for the samples\n",
        "        test_samples = pd.DataFrame(columns=test_df.columns)\n",
        "\n",
        "        # Sample from each class proportionally\n",
        "        for label, proportion in label_counts.items():\n",
        "            # Calculate how many samples to take from this class\n",
        "            class_sample_size = int(np.ceil(sample_size * proportion))\n",
        "            class_data = test_df[test_df['Label'] == label]\n",
        "\n",
        "            # If there are fewer rows than the requested sample size, take all rows\n",
        "            if len(class_data) <= class_sample_size:\n",
        "                class_samples = class_data\n",
        "            else:\n",
        "                class_samples = class_data.sample(class_sample_size, random_state=random_seed)\n",
        "\n",
        "            # Add to the samples DataFrame\n",
        "            test_samples = pd.concat([test_samples, class_samples])\n",
        "\n",
        "        # If we have more samples than requested, take a random subsample\n",
        "        if len(test_samples) > sample_size:\n",
        "            test_samples = test_samples.sample(sample_size, random_state=random_seed)\n",
        "    else:\n",
        "        # Take a simple random sample if no 'Label' column\n",
        "        print(\"Taking random sample from test dataset...\")\n",
        "        test_samples = test_df.sample(sample_size, random_state=random_seed)\n",
        "\n",
        "    print(f\"Selected {len(test_samples)} samples from test dataset\")\n",
        "\n",
        "    # Add a column to track the source of the data (optional)\n",
        "    if 'data_source' not in train_df.columns and 'data_source' not in test_samples.columns:\n",
        "        train_df['data_source'] = 'original_train'\n",
        "        test_samples['data_source'] = 'test_sample'\n",
        "\n",
        "    # Combine datasets\n",
        "    enhanced_df = pd.concat([train_df, test_samples], ignore_index=True)\n",
        "    print(f\"Enhanced training dataset: {len(enhanced_df)} rows\")\n",
        "\n",
        "    # Shuffle the data\n",
        "    enhanced_df = enhanced_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
        "\n",
        "    # Save to output file\n",
        "    print(f\"Saving enhanced dataset to {output_file}...\")\n",
        "    enhanced_df.to_csv(output_file, sep='\\t', index=False)\n",
        "    print(\"Done!\")\n",
        "\n",
        "    return enhanced_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Example file paths\n",
        "    train_file = \"train.csv\"  # Combined Monday-Wednesday data\n",
        "    test_file = \"test.csv\"  # Combined Thursday-Friday data\n",
        "    output_file = \"enhanced_train.csv\"\n",
        "\n",
        "    # Enhance training data with 1000 random samples from test data\n",
        "    enhanced_df = enhance_training_data(train_file, test_file, output_file, k_samples=1000)\n",
        "\n",
        "    if enhanced_df is not None:\n",
        "        # Print class distribution if 'Label' column exists\n",
        "        if 'Label' in enhanced_df.columns:\n",
        "            print(\"\\nClass distribution in enhanced dataset:\")\n",
        "            print(enhanced_df['Label'].value_counts())\n",
        "\n",
        "            # Print distribution by source\n",
        "            if 'data_source' in enhanced_df.columns:\n",
        "                print(\"\\nSamples by source:\")\n",
        "                print(enhanced_df['data_source'].value_counts())"
      ],
      "metadata": {
        "id": "hXnhawfz58QC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60bdedc8-e587-4d7b-9133-1e110873d2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enhancing training data with 1000 samples from test data...\n",
            "Reading training file: train.csv\n",
            "  Training data: 1190343 rows, 1 columns\n",
            "Reading test file: test.csv\n",
            "  Test data: 909633 rows, 1 columns\n",
            "Taking random sample from test dataset...\n",
            "Selected 1000 samples from test dataset\n",
            "Enhanced training dataset: 1191343 rows\n",
            "Saving enhanced dataset to enhanced_train.csv...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L_ryeERs58NH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VrQRnILi58IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, roc_curve, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score, classification_report\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Load network flow data from file path, attempting multiple delimiters.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # First try tab delimiter\n",
        "        df = pd.read_csv(file_path, delimiter='\\t')\n",
        "\n",
        "        # Check if we ended up with only one column containing all data\n",
        "        if len(df.columns) == 1 and ',' in df.iloc[0, 0]:\n",
        "            print(\"Data loaded as a single column. Trying comma delimiter...\")\n",
        "\n",
        "            # Try with comma delimiter\n",
        "            df = pd.read_csv(file_path, delimiter=',')\n",
        "            print(f\"Loaded dataset with comma delimiter. Shape: {df.shape}\")\n",
        "            return df\n",
        "\n",
        "        print(f\"Loaded dataset with tab delimiter. Shape: {df.shape}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error with standard loading: {e}\")\n",
        "\n",
        "        # Try a manual approach\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            # Detect delimiter from first line\n",
        "            first_line = lines[0].strip()\n",
        "            if '\\t' in first_line and ',' in first_line:\n",
        "                # If both tab and comma exist, use the one that gives more splits\n",
        "                tab_count = first_line.count('\\t')\n",
        "                comma_count = first_line.count(',')\n",
        "                delimiter = '\\t' if tab_count > comma_count else ','\n",
        "            elif '\\t' in first_line:\n",
        "                delimiter = '\\t'\n",
        "            elif ',' in first_line:\n",
        "                delimiter = ','\n",
        "            else:\n",
        "                delimiter = ',' # Default to comma\n",
        "\n",
        "            print(f\"Using manual parsing with delimiter: '{delimiter}'\")\n",
        "\n",
        "            # Parse manually\n",
        "            headers = lines[0].strip().split(delimiter)\n",
        "            data = []\n",
        "\n",
        "            for i in range(1, len(lines)):\n",
        "                if lines[i].strip():  # Skip empty lines\n",
        "                    row = lines[i].strip().split(delimiter)\n",
        "                    if len(row) == len(headers):\n",
        "                        data.append(row)\n",
        "                    else:\n",
        "                        print(f\"Warning: Line {i+1} has {len(row)} fields, expected {len(headers)}\")\n",
        "\n",
        "            df = pd.DataFrame(data, columns=headers)\n",
        "            print(f\"Manually loaded dataset with shape: {df.shape}\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"Error with manual parsing: {e}\")\n",
        "            raise\n",
        "\n",
        "def preprocess_data(df, scaler=None, fit_scaler=False):\n",
        "    \"\"\"\n",
        "    Preprocess the network flow data according to paper specifications:\n",
        "    - Remove flow identifiers\n",
        "    - Apply min-max normalization\n",
        "    - Convert labels to binary format\n",
        "\n",
        "    Args:\n",
        "        df: The dataframe to preprocess\n",
        "        scaler: An optional pre-fitted scaler (for test data)\n",
        "        fit_scaler: Whether to fit the scaler on this data (for train data)\n",
        "\n",
        "    Returns:\n",
        "        Preprocessed dataframe and the scaler (if fit_scaler=True)\n",
        "    \"\"\"\n",
        "    print(\"\\nPreprocessing data:\")\n",
        "    print(f\"Initial columns: {df.columns.tolist()[:5]}... (total: {len(df.columns)})\")\n",
        "\n",
        "    # Make a copy to avoid modifying the original\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Convert label column to binary (0 for BENIGN, 1 for attacks)\n",
        "    if 'Label' in df_processed.columns:\n",
        "        df_processed['Label_Binary'] = df_processed['Label'].apply(lambda x: 0 if str(x).upper() == 'BENIGN' else 1)\n",
        "        # Save the original labels for detailed analysis later\n",
        "        df_processed['Original_Label'] = df_processed['Label']\n",
        "        label_counts = df_processed['Label'].value_counts()\n",
        "        print(f\"Label distribution: {label_counts.to_dict()}\")\n",
        "        binary_counts = df_processed['Label_Binary'].value_counts()\n",
        "        print(f\"Binary label distribution: {binary_counts.to_dict()}\")\n",
        "\n",
        "    # Remove flow identifiers as specified\n",
        "    columns_to_drop = [\n",
        "        'id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Timestamp',\n",
        "        'ICMP Code', 'ICMP Type', 'Total TCP Flow Time', 'Attempted Category', 'Label'\n",
        "    ]\n",
        "\n",
        "    # Drop TTL-based features if they exist\n",
        "    ttl_features = [col for col in df_processed.columns if 'TTL' in col]\n",
        "    columns_to_drop.extend(ttl_features)\n",
        "\n",
        "    # Only drop columns that exist in the dataframe\n",
        "    columns_to_drop = [col for col in columns_to_drop if col in df_processed.columns]\n",
        "    df_cleaned = df_processed.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "    # Convert all columns to numeric, coercing errors to NaN\n",
        "    numeric_cols = []\n",
        "    for col in df_cleaned.columns:\n",
        "        if col != 'Label_Binary' and col != 'Original_Label':\n",
        "            try:\n",
        "                df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
        "                numeric_cols.append(col)\n",
        "            except Exception as e:\n",
        "                print(f\"Error converting column {col} to numeric: {e}\")\n",
        "                df_cleaned = df_cleaned.drop(columns=[col])\n",
        "\n",
        "    # Display info about numeric columns\n",
        "    print(f\"Number of numeric columns after conversion: {len(numeric_cols)}\")\n",
        "    if len(numeric_cols) == 0:\n",
        "        raise ValueError(\"No numeric columns available after preprocessing\")\n",
        "\n",
        "    # Handle NaN values\n",
        "    print(f\"NaN values before handling: {df_cleaned[numeric_cols].isna().sum().sum()}\")\n",
        "\n",
        "    # Replace infinity values with NaN\n",
        "    df_cleaned = df_cleaned.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Check for columns with all NaN values\n",
        "    null_cols = [col for col in numeric_cols if df_cleaned[col].isna().all()]\n",
        "    if null_cols:\n",
        "        print(f\"Dropping columns with all NaN values: {null_cols}\")\n",
        "        df_cleaned = df_cleaned.drop(columns=null_cols)\n",
        "        numeric_cols = [col for col in numeric_cols if col not in null_cols]\n",
        "\n",
        "    # Fill remaining NaN values with column means\n",
        "    for col in numeric_cols:\n",
        "        if df_cleaned[col].isna().any():\n",
        "            col_mean = df_cleaned[col].mean()\n",
        "            df_cleaned[col] = df_cleaned[col].fillna(col_mean)\n",
        "\n",
        "    print(f\"NaN values after handling: {df_cleaned[numeric_cols].isna().sum().sum()}\")\n",
        "\n",
        "    # Verify we have data to work with\n",
        "    if len(numeric_cols) == 0:\n",
        "        raise ValueError(\"No numeric columns available after preprocessing\")\n",
        "\n",
        "    # Apply min-max scaling to all numeric columns\n",
        "    if 'Label_Binary' in df_cleaned.columns:\n",
        "        features = df_cleaned[numeric_cols]\n",
        "        labels = df_cleaned['Label_Binary']\n",
        "        original_labels = df_cleaned.get('Original_Label', None)\n",
        "    else:\n",
        "        features = df_cleaned[numeric_cols]\n",
        "        labels = None\n",
        "        original_labels = None\n",
        "\n",
        "    # Apply scaling\n",
        "    if scaler is None and fit_scaler:\n",
        "        scaler = MinMaxScaler()\n",
        "        scaled_features = scaler.fit_transform(features)\n",
        "    elif scaler is not None:\n",
        "        scaled_features = scaler.transform(features)\n",
        "    else:\n",
        "        raise ValueError(\"Either provide a fitted scaler or set fit_scaler=True\")\n",
        "\n",
        "    # Create a new dataframe with scaled features\n",
        "    scaled_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
        "\n",
        "    # Add back the label columns if they exist\n",
        "    if labels is not None:\n",
        "        scaled_df['Label_Binary'] = labels.values\n",
        "    if original_labels is not None:\n",
        "        scaled_df['Original_Label'] = original_labels.values\n",
        "\n",
        "    print(f\"Preprocessed dataset shape: {scaled_df.shape}\")\n",
        "\n",
        "    if fit_scaler:\n",
        "        return scaled_df, scaler\n",
        "    else:\n",
        "        return scaled_df\n",
        "\n",
        "def evaluate_performance(y_true, y_pred, y_scores, prediction_time, original_labels=None):\n",
        "    \"\"\"Calculate all required performance metrics.\"\"\"\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Calculate AUC - handle case where all predictions are the same class\n",
        "    try:\n",
        "        auc_score = roc_auc_score(y_true, y_scores)\n",
        "    except:\n",
        "        auc_score = 0.5  # Default value when AUC can't be calculated\n",
        "        print(\"Warning: AUC could not be calculated, possibly due to only one class present\")\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # Calculate precision and recall\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Ensure confusion matrix has correct shape for metrics calculation\n",
        "    if cm.shape == (1, 1):  # Only one class predicted\n",
        "        if y_true[0] == 1:  # Only positive class exists\n",
        "            tn, fp, fn, tp = 0, 0, 0, cm[0, 0]\n",
        "        else:  # Only negative class exists\n",
        "            tn, fp, fn, tp = cm[0, 0], 0, 0, 0\n",
        "    elif cm.shape == (2, 1) or cm.shape == (1, 2):  # Handle imbalanced confusion matrix\n",
        "        if cm.size == 2:  # We have two elements\n",
        "            if 1 in y_pred:  # We predicted positive at least once\n",
        "                tn = 0\n",
        "                fp = (y_true == 0).sum() - tn\n",
        "                tp = (y_true == 1).sum() - 0  # All positive samples are TP\n",
        "                fn = 0\n",
        "            else:  # We predicted negative for all\n",
        "                tn = (y_true == 0).sum()\n",
        "                fp = 0\n",
        "                tp = 0\n",
        "                fn = (y_true == 1).sum()\n",
        "    else:  # Normal case\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    # Calculate Detection Rate (DR) and False Alarm Rate (FAR)\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "\n",
        "    # Store all metrics\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'AUC': auc_score,\n",
        "        'Detection Rate (DR)': detection_rate,\n",
        "        'False Alarm Rate (FAR)': false_alarm_rate,\n",
        "        'True Negatives': tn,\n",
        "        'False Positives': fp,\n",
        "        'False Negatives': fn,\n",
        "        'True Positives': tp,\n",
        "        'Prediction Time (Î¼s/sample)': prediction_time\n",
        "    }\n",
        "\n",
        "    # Create a detailed analysis of false positives and false negatives\n",
        "    fp_fn_analysis = {}\n",
        "    if original_labels is not None:\n",
        "        # Get indices of false positives and false negatives\n",
        "        fp_indices = np.where((y_true == 0) & (y_pred == 1))[0]\n",
        "        fn_indices = np.where((y_true == 1) & (y_pred == 0))[0]\n",
        "\n",
        "        # Count occurrence of each attack type in false negatives\n",
        "        if len(fn_indices) > 0:\n",
        "            fn_attack_types = original_labels.iloc[fn_indices].value_counts()\n",
        "            fp_fn_analysis['False Negative Types'] = fn_attack_types.to_dict()\n",
        "\n",
        "        # For false positives, they are all benign\n",
        "        fp_fn_analysis['False Positive Count'] = len(fp_indices)\n",
        "\n",
        "    return metrics, fp_fn_analysis\n",
        "\n",
        "def main():\n",
        "    # Load the training data\n",
        "    try:\n",
        "        print(\"Loading training data...\")\n",
        "        train_df = load_data('train_dataset_b.csv')\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading training data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Load the test data\n",
        "    try:\n",
        "        print(\"Loading test data...\")\n",
        "        test_df = load_data('balanced_10k_test.csv')\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading test data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Display data summary\n",
        "    print(\"\\nTraining data summary:\")\n",
        "    print(f\"Columns: {train_df.columns.tolist()[:5]} ... (total: {len(train_df.columns)})\")\n",
        "    print(f\"Number of samples: {len(train_df)}\")\n",
        "\n",
        "    print(\"\\nTest data summary:\")\n",
        "    print(f\"Columns: {test_df.columns.tolist()[:5]} ... (total: {len(test_df.columns)})\")\n",
        "    print(f\"Number of samples: {len(test_df)}\")\n",
        "\n",
        "    # Preprocess the training data\n",
        "    try:\n",
        "        print(\"\\nPreprocessing training data...\")\n",
        "        train_processed, scaler = preprocess_data(train_df, fit_scaler=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error preprocessing training data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Preprocess the test data using the same scaler\n",
        "    try:\n",
        "        print(\"\\nPreprocessing test data...\")\n",
        "        test_processed = preprocess_data(test_df, scaler=scaler, fit_scaler=False)\n",
        "    except Exception as e:\n",
        "        print(f\"Error preprocessing test data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Check if we have the necessary binary label column in both datasets\n",
        "    if 'Label_Binary' not in train_processed.columns:\n",
        "        print(\"No 'Label_Binary' column found in training data after preprocessing. Cannot proceed.\")\n",
        "        return\n",
        "\n",
        "    if 'Label_Binary' not in test_processed.columns:\n",
        "        print(\"No 'Label_Binary' column found in test data after preprocessing. Cannot proceed.\")\n",
        "        return\n",
        "\n",
        "    # Check label distribution in training data\n",
        "    train_label_dist = train_processed['Label_Binary'].value_counts()\n",
        "    print(f\"\\nTraining data label distribution: {train_label_dist.to_dict()}\")\n",
        "\n",
        "    # Check label distribution in test data\n",
        "    test_label_dist = test_processed['Label_Binary'].value_counts()\n",
        "    print(f\"Test data label distribution: {test_label_dist.to_dict()}\")\n",
        "\n",
        "    # Handle case where only one class is present in either dataset\n",
        "    if train_processed['Label_Binary'].nunique() < 2:\n",
        "        print(f\"Warning: Only one class present in training data ({train_processed['Label_Binary'].unique()[0]})\")\n",
        "        print(\"Generating synthetic data for demonstration purposes...\")\n",
        "\n",
        "        # Generate synthetic attack samples\n",
        "        majority_class = train_processed['Label_Binary'].mode()[0]\n",
        "        minority_class = 1 if majority_class == 0 else 0\n",
        "\n",
        "        majority_data = train_processed[train_processed['Label_Binary'] == majority_class]\n",
        "\n",
        "        # Create synthetic minority samples\n",
        "        num_samples = min(int(len(majority_data) * 0.3), 500)\n",
        "        synthetic_samples = majority_data.sample(num_samples, replace=(num_samples > len(majority_data)))\n",
        "\n",
        "        # Add noise to make them different\n",
        "        for col in synthetic_samples.columns:\n",
        "            if col != 'Label_Binary' and col != 'Original_Label':\n",
        "                noise = np.random.normal(0, 0.1, size=len(synthetic_samples))\n",
        "                synthetic_samples[col] = synthetic_samples[col] + noise\n",
        "                synthetic_samples[col] = synthetic_samples[col].clip(0, 1)\n",
        "\n",
        "        # Set minority class\n",
        "        synthetic_samples['Label_Binary'] = minority_class\n",
        "\n",
        "        # Set a dummy original label for synthetic samples\n",
        "        if 'Original_Label' in synthetic_samples.columns:\n",
        "            synthetic_samples['Original_Label'] = 'SYNTHETIC_ATTACK' if minority_class == 1 else 'SYNTHETIC_BENIGN'\n",
        "\n",
        "        # Combine with original data\n",
        "        train_processed = pd.concat([train_processed, synthetic_samples], ignore_index=True)\n",
        "        print(f\"Added {num_samples} synthetic samples of class {minority_class}\")\n",
        "        print(f\"New training label distribution: {train_processed['Label_Binary'].value_counts().to_dict()}\")\n",
        "\n",
        "    # Get the original labels for detailed analysis\n",
        "    original_labels_test = test_processed.get('Original_Label', None)\n",
        "\n",
        "    # Split features and target for training data\n",
        "    X_train = train_processed.drop(['Label_Binary'], axis=1)\n",
        "    if 'Original_Label' in X_train.columns:\n",
        "        X_train = X_train.drop(['Original_Label'], axis=1)\n",
        "    y_train = train_processed['Label_Binary']\n",
        "\n",
        "    # Split features and target for test data\n",
        "    X_test = test_processed.drop(['Label_Binary'], axis=1)\n",
        "    if 'Original_Label' in X_test.columns:\n",
        "        X_test = X_test.drop(['Original_Label'], axis=1)\n",
        "    y_test = test_processed['Label_Binary']\n",
        "\n",
        "    print(f\"\\nTraining features shape: {X_train.shape}\")\n",
        "    print(f\"Training target shape: {y_train.shape}\")\n",
        "    print(f\"Test features shape: {X_test.shape}\")\n",
        "    print(f\"Test target shape: {y_test.shape}\")\n",
        "\n",
        "    # Initialize XGBoost classifier\n",
        "    model = xgb.XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "\n",
        "    # Train the model on the entire training set\n",
        "    print(\"\\nTraining XGBoost model...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Measure prediction time on test set\n",
        "    print(\"\\nEvaluating on test set...\")\n",
        "    start_time = time.time()\n",
        "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate prediction time per sample in microseconds\n",
        "    test_prediction_time = (end_time - start_time) * 1000000 / len(X_test)\n",
        "\n",
        "    # Calculate final metrics and get detailed false positive/negative analysis\n",
        "    test_metrics, fp_fn_analysis = evaluate_performance(y_test, y_test_pred, y_test_pred_proba,\n",
        "                                                       test_prediction_time, original_labels_test)\n",
        "\n",
        "    # Print test metrics\n",
        "    print(\"\\nTest set performance metrics:\")\n",
        "    for metric_name, metric_value in test_metrics.items():\n",
        "        print(f\"  {metric_name}: {metric_value:.6f}\")\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nDetailed classification report:\")\n",
        "    print(classification_report(y_test, y_test_pred, zero_division=0))\n",
        "\n",
        "    # Print false positive and false negative analysis\n",
        "    print(\"\\nFalse Positive and False Negative Analysis:\")\n",
        "    if 'False Negative Types' in fp_fn_analysis:\n",
        "        print(\"  False Negative breakdown by attack type:\")\n",
        "        for attack_type, count in fp_fn_analysis['False Negative Types'].items():\n",
        "            print(f\"    {attack_type}: {count}\")\n",
        "\n",
        "    print(f\"  Total False Positives: {test_metrics['False Positives']}\")\n",
        "    print(f\"  Total False Negatives: {test_metrics['False Negatives']}\")\n",
        "\n",
        "    try:\n",
        "        # Create directory for plots if it doesn't exist\n",
        "        import os\n",
        "        if not os.path.exists('plots'):\n",
        "            os.makedirs('plots')\n",
        "\n",
        "        # Plot ROC curve\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.plot(fpr, tpr, label=f'AUC = {test_metrics[\"AUC\"]:.4f}')\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('ROC Curve')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.grid(True)\n",
        "        plt.savefig('plots/roc_curve.png')\n",
        "        print(\"\\nROC curve saved as 'plots/roc_curve.png'\")\n",
        "        plt.close()\n",
        "\n",
        "        # Plot confusion matrix with percentages\n",
        "        cm = confusion_matrix(y_test, y_test_pred)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.savefig('plots/confusion_matrix.png')\n",
        "        print(\"Confusion matrix saved as 'plots/confusion_matrix.png'\")\n",
        "        plt.close()\n",
        "\n",
        "        # Plot normalized confusion matrix\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.title('Normalized Confusion Matrix')\n",
        "        plt.savefig('plots/normalized_confusion_matrix.png')\n",
        "        print(\"Normalized confusion matrix saved as 'plots/normalized_confusion_matrix.png'\")\n",
        "        plt.close()\n",
        "\n",
        "        # Create a more detailed visualization of FP and FN\n",
        "        # Set up the figure with 2 subplots\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "        # Left plot: False Negative Distribution by Type (if available)\n",
        "        if 'False Negative Types' in fp_fn_analysis and len(fp_fn_analysis['False Negative Types']) > 0:\n",
        "            fn_types = pd.Series(fp_fn_analysis['False Negative Types'])\n",
        "            fn_types.sort_values(ascending=False).plot(kind='bar', ax=ax1, color='salmon')\n",
        "            ax1.set_title('False Negatives by Attack Type')\n",
        "            ax1.set_ylabel('Count')\n",
        "            ax1.set_xlabel('Attack Type')\n",
        "            ax1.tick_params(axis='x', rotation=90)\n",
        "        else:\n",
        "            ax1.text(0.5, 0.5, 'No False Negatives Available',\n",
        "                    horizontalalignment='center', verticalalignment='center')\n",
        "            ax1.set_title('False Negatives Analysis')\n",
        "\n",
        "        # Right plot: Metrics Comparison\n",
        "        metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC']\n",
        "        values = [test_metrics[metric] for metric in metrics_to_plot]\n",
        "        ax2.bar(metrics_to_plot, values, color='lightblue')\n",
        "        ax2.set_title('Performance Metrics')\n",
        "        ax2.set_ylim(0, 1)\n",
        "        ax2.set_ylabel('Score')\n",
        "        ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('plots/detailed_performance.png')\n",
        "        print(\"Detailed performance metrics saved as 'plots/detailed_performance.png'\")\n",
        "        plt.close()\n",
        "\n",
        "        # Plot feature importance\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        xgb.plot_importance(model, max_num_features=20)\n",
        "        plt.title('Feature Importance')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('plots/feature_importance.png')\n",
        "        print(\"Feature importance plot saved as 'plots/feature_importance.png'\")\n",
        "        plt.close()\n",
        "\n",
        "        # Generate precision-recall curve\n",
        "        from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_test_pred_proba)\n",
        "        avg_precision = average_precision_score(y_test, y_test_pred_proba)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.plot(recall, precision, label=f'Average Precision = {avg_precision:.4f}')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('Precision-Recall Curve')\n",
        "        plt.legend(loc='best')\n",
        "        plt.grid(True)\n",
        "        plt.savefig('plots/precision_recall_curve.png')\n",
        "        print(\"Precision-recall curve saved as 'plots/precision_recall_curve.png'\")\n",
        "        plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating plots: {e}\")\n",
        "\n",
        "    print(\"\\nAnalysis complete!\")\n",
        "\n",
        "    # Print a note about synthetic data if it was used\n",
        "    if train_df['Label'].nunique() < 2 or train_processed['Label_Binary'].nunique() < 2:\n",
        "        print(\"\\nNOTE: This analysis used synthetic data for demonstration purposes.\")\n",
        "        print(\"In a real-world scenario, you would need balanced class representation for meaningful results.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ZY_6pIqo5Wzt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4f7c6f56-e3f2-43e3-894f-510ff5876a23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data...\n",
            "Data loaded as a single column. Trying comma delimiter...\n",
            "Loaded dataset with comma delimiter. Shape: (1190343, 91)\n",
            "Loading test data...\n",
            "Data loaded as a single column. Trying comma delimiter...\n",
            "Loaded dataset with comma delimiter. Shape: (10000, 91)\n",
            "\n",
            "Training data summary:\n",
            "Columns: ['id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP'] ... (total: 91)\n",
            "Number of samples: 1190343\n",
            "\n",
            "Test data summary:\n",
            "Columns: ['id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP'] ... (total: 91)\n",
            "Number of samples: 10000\n",
            "\n",
            "Preprocessing training data...\n",
            "\n",
            "Preprocessing data:\n",
            "Initial columns: ['id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP']... (total: 91)\n",
            "Label distribution: {'BENIGN': 1005850, 'DoS Hulk': 158468, 'DoS GoldenEye': 7567, 'FTP-Patator': 3972, 'DoS Slowloris': 3859, 'DoS Slowhttptest - Attempted': 3368, 'SSH-Patator': 2961, 'DoS Slowloris - Attempted': 1847, 'DoS Slowhttptest': 1740, 'DoS Hulk - Attempted': 581, 'DoS GoldenEye - Attempted': 80, 'SSH-Patator - Attempted': 27, 'FTP-Patator - Attempted': 12, 'Heartbleed': 11}\n",
            "Binary label distribution: {0: 1005850, 1: 184493}\n",
            "Number of numeric columns after conversion: 79\n",
            "NaN values before handling: 0\n",
            "NaN values after handling: 0\n",
            "Preprocessed dataset shape: (1190343, 81)\n",
            "\n",
            "Preprocessing test data...\n",
            "\n",
            "Preprocessing data:\n",
            "Initial columns: ['id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP']... (total: 91)\n",
            "Label distribution: {'BENIGN': 5000, 'Portscan': 2401, 'DDoS': 1391, 'Infiltration - Portscan': 1107, 'Botnet - Attempted': 60, 'Web Attack - Brute Force - Attempted': 18, 'Web Attack - XSS - Attempted': 12, 'Botnet': 11}\n",
            "Binary label distribution: {1: 5000, 0: 5000}\n",
            "Number of numeric columns after conversion: 79\n",
            "NaN values before handling: 0\n",
            "NaN values after handling: 0\n",
            "Preprocessed dataset shape: (10000, 81)\n",
            "\n",
            "Training data label distribution: {0: 1005850, 1: 184493}\n",
            "Test data label distribution: {1: 5000, 0: 5000}\n",
            "\n",
            "Training features shape: (1190343, 79)\n",
            "Training target shape: (1190343,)\n",
            "Test features shape: (10000, 79)\n",
            "Test target shape: (10000,)\n",
            "\n",
            "Training XGBoost model...\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test set performance metrics:\n",
            "  Accuracy: 0.499800\n",
            "  Precision: 0.000000\n",
            "  Recall: 0.000000\n",
            "  F1 Score: 0.000000\n",
            "  AUC: 0.966451\n",
            "  Detection Rate (DR): 0.000000\n",
            "  False Alarm Rate (FAR): 0.000400\n",
            "  True Negatives: 4998.000000\n",
            "  False Positives: 2.000000\n",
            "  False Negatives: 5000.000000\n",
            "  True Positives: 0.000000\n",
            "  Prediction Time (Î¼s/sample): 8.157229\n",
            "\n",
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67      5000\n",
            "           1       0.00      0.00      0.00      5000\n",
            "\n",
            "    accuracy                           0.50     10000\n",
            "   macro avg       0.25      0.50      0.33     10000\n",
            "weighted avg       0.25      0.50      0.33     10000\n",
            "\n",
            "\n",
            "False Positive and False Negative Analysis:\n",
            "  False Negative breakdown by attack type:\n",
            "    Portscan: 2401\n",
            "    DDoS: 1391\n",
            "    Infiltration - Portscan: 1107\n",
            "    Botnet - Attempted: 60\n",
            "    Web Attack - Brute Force - Attempted: 18\n",
            "    Web Attack - XSS - Attempted: 12\n",
            "    Botnet: 11\n",
            "  Total False Positives: 2\n",
            "  Total False Negatives: 5000\n",
            "\n",
            "ROC curve saved as 'plots/roc_curve.png'\n",
            "Confusion matrix saved as 'plots/confusion_matrix.png'\n",
            "Normalized confusion matrix saved as 'plots/normalized_confusion_matrix.png'\n",
            "Detailed performance metrics saved as 'plots/detailed_performance.png'\n",
            "Feature importance plot saved as 'plots/feature_importance.png'\n",
            "Precision-recall curve saved as 'plots/precision_recall_curve.png'\n",
            "\n",
            "Analysis complete!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5XUuuXEo5WvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "def fix_csv_files(input_files, output_file):\n",
        "    \"\"\"\n",
        "    Fix and combine multiple CSV files that may have formatting issues\n",
        "\n",
        "    Args:\n",
        "        input_files (list): List of input CSV file paths\n",
        "        output_file (str): Output file path\n",
        "    \"\"\"\n",
        "    # Create an empty list to store dataframes\n",
        "    dfs = []\n",
        "\n",
        "    # Process each input file\n",
        "    for file_path in input_files:\n",
        "        print(f\"Processing {file_path}...\")\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"  Warning: {file_path} does not exist. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Try to determine the actual delimiter and structure\n",
        "            with open(file_path, 'r') as f:\n",
        "                first_line = f.readline().strip()\n",
        "\n",
        "            # Check if this is a malformed file (common format issue)\n",
        "            # This happens when a CSV is saved with tab delimiters but all data is in first column\n",
        "            if '\\t' in first_line and ',' in first_line and first_line.count('\\t') < first_line.count(','):\n",
        "                print(f\"  Detected malformed CSV. Attempting to fix...\")\n",
        "\n",
        "                # Try reading the file using comma delimiter\n",
        "                df = pd.read_csv(file_path, sep=',')\n",
        "\n",
        "                # Check if we got a reasonable number of columns\n",
        "                if len(df.columns) > 5:  # Arbitrary threshold\n",
        "                    print(f\"  Successfully parsed with comma delimiter: {len(df)} rows, {len(df.columns)} columns\")\n",
        "                    dfs.append(df)\n",
        "                    continue\n",
        "\n",
        "                # If we couldn't parse it properly, try manual fixing\n",
        "                with open(file_path, 'r') as f:\n",
        "                    lines = f.readlines()\n",
        "\n",
        "                # Get the headers - assume they're comma-separated in the first line\n",
        "                headers = [h.strip() for h in lines[0].strip().split(',')]\n",
        "\n",
        "                # Create a temporary fixed file\n",
        "                temp_file = file_path + \".fixed.csv\"\n",
        "                with open(temp_file, 'w') as f:\n",
        "                    # Write the headers as comma-separated\n",
        "                    f.write(','.join(headers) + '\\n')\n",
        "\n",
        "                    # Process each line after the header\n",
        "                    for i in range(1, len(lines)):\n",
        "                        if lines[i].strip():  # Skip empty lines\n",
        "                            # If line contains tabs, it might be tab-separated but with commas in fields\n",
        "                            if '\\t' in lines[i]:\n",
        "                                # Split by tab, then join back with commas\n",
        "                                fields = lines[i].strip().split('\\t')\n",
        "\n",
        "                                # If we get exactly one field, it's likely all packed into first column\n",
        "                                if len(fields) == 1:\n",
        "                                    # The field might already have commas, so use it directly\n",
        "                                    f.write(fields[0] + '\\n')\n",
        "                                else:\n",
        "                                    # It's genuinely tab-separated, convert to comma\n",
        "                                    f.write(','.join(fields) + '\\n')\n",
        "                            else:\n",
        "                                # Already comma-separated, write as is\n",
        "                                f.write(lines[i])\n",
        "\n",
        "                # Now read the fixed file\n",
        "                df = pd.read_csv(temp_file)\n",
        "                print(f\"  Fixed and loaded: {len(df)} rows, {len(df.columns)} columns\")\n",
        "                dfs.append(df)\n",
        "\n",
        "                # Clean up the temporary file\n",
        "                os.remove(temp_file)\n",
        "\n",
        "            elif '\\t' in first_line:\n",
        "                # Try tab delimiter first\n",
        "                df = pd.read_csv(file_path, sep='\\t')\n",
        "\n",
        "                # Check if we have more than one column\n",
        "                if len(df.columns) == 1 and ',' in df.iloc[0, 0]:\n",
        "                    print(\"  Data loaded as a single column. Trying comma delimiter...\")\n",
        "                    df = pd.read_csv(file_path, sep=',')\n",
        "\n",
        "                print(f\"  Loaded dataset: {len(df)} rows, {len(df.columns)} columns\")\n",
        "                dfs.append(df)\n",
        "\n",
        "            elif ',' in first_line:\n",
        "                # Try comma delimiter\n",
        "                df = pd.read_csv(file_path, sep=',')\n",
        "                print(f\"  Loaded dataset: {len(df)} rows, {len(df.columns)} columns\")\n",
        "                dfs.append(df)\n",
        "\n",
        "            else:\n",
        "                # Try both common delimiters\n",
        "                try:\n",
        "                    df = pd.read_csv(file_path, sep=',')\n",
        "                    print(f\"  Loaded with comma delimiter: {len(df)} rows, {len(df.columns)} columns\")\n",
        "                    dfs.append(df)\n",
        "                except:\n",
        "                    try:\n",
        "                        df = pd.read_csv(file_path, sep='\\t')\n",
        "                        print(f\"  Loaded with tab delimiter: {len(df)} rows, {len(df.columns)} columns\")\n",
        "                        dfs.append(df)\n",
        "                    except Exception as e:\n",
        "                        print(f\"  Error parsing file with standard delimiters: {e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error processing {file_path}: {e}\")\n",
        "\n",
        "    # Concatenate all dataframes if we have any\n",
        "    if dfs:\n",
        "        # Check if all dataframes have the same columns\n",
        "        all_columns = [set(df.columns) for df in dfs]\n",
        "        if len(set.union(*all_columns)) > len(set.intersection(*all_columns)):\n",
        "            print(\"\\nWarning: Not all files have the same columns!\")\n",
        "            print(f\"  Total unique columns across all files: {len(set.union(*all_columns))}\")\n",
        "            print(f\"  Common columns across all files: {len(set.intersection(*all_columns))}\")\n",
        "\n",
        "            # Use only common columns for consistent concatenation\n",
        "            common_columns = list(set.intersection(*all_columns))\n",
        "            print(f\"  Using only common columns: {len(common_columns)}\")\n",
        "\n",
        "            # Filter each dataframe to only include common columns\n",
        "            dfs = [df[common_columns] for df in dfs]\n",
        "\n",
        "        # Now concatenate\n",
        "        combined_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "        # Write to output file - using comma as a standard delimiter\n",
        "        print(f\"\\nWriting {len(combined_df)} rows to {output_file}...\")\n",
        "        combined_df.to_csv(output_file, index=False)\n",
        "        print(\"Done!\")\n",
        "\n",
        "        # Return the combined dataframe\n",
        "        return combined_df\n",
        "    else:\n",
        "        print(\"No data to combine!\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def enhance_training_data(train_file, test_file, output_file, k_samples=1000, random_seed=42):\n",
        "    \"\"\"\n",
        "    Enhance training dataset by including K random samples from the test dataset.\n",
        "\n",
        "    Args:\n",
        "        train_file (str): Path to the training CSV file (e.g., combined Mon-Wed)\n",
        "        test_file (str): Path to the test CSV file (e.g., combined Thu-Fri)\n",
        "        output_file (str): Path to save the enhanced training dataset\n",
        "        k_samples (int): Number of random samples to include from test dataset\n",
        "        random_seed (int): Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The enhanced training dataset\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    print(f\"Enhancing training data with {k_samples} samples from test data...\")\n",
        "\n",
        "    # Check if files exist\n",
        "    for file in [train_file, test_file]:\n",
        "        if not os.path.exists(file):\n",
        "            raise FileNotFoundError(f\"File not found: {file}\")\n",
        "\n",
        "    # Read the datasets - trying to handle potential format issues\n",
        "    try:\n",
        "        print(f\"Reading training file: {train_file}\")\n",
        "        try:\n",
        "            train_df = pd.read_csv(train_file, sep=',')\n",
        "        except:\n",
        "            try:\n",
        "                train_df = pd.read_csv(train_file, sep='\\t')\n",
        "            except:\n",
        "                # Try to detect delimiter\n",
        "                with open(train_file, 'r') as f:\n",
        "                    first_line = f.readline().strip()\n",
        "                if '\\t' in first_line and ',' in first_line:\n",
        "                    # If both delimiters exist, use the one that gives more splits\n",
        "                    tab_count = first_line.count('\\t')\n",
        "                    comma_count = first_line.count(',')\n",
        "                    delimiter = '\\t' if tab_count > comma_count else ','\n",
        "                elif '\\t' in first_line:\n",
        "                    delimiter = '\\t'\n",
        "                else:\n",
        "                    delimiter = ','\n",
        "\n",
        "                train_df = pd.read_csv(train_file, sep=delimiter)\n",
        "\n",
        "        print(f\"  Training data: {len(train_df)} rows, {len(train_df.columns)} columns\")\n",
        "\n",
        "        print(f\"Reading test file: {test_file}\")\n",
        "        try:\n",
        "            test_df = pd.read_csv(test_file, sep=',')\n",
        "        except:\n",
        "            try:\n",
        "                test_df = pd.read_csv(test_file, sep='\\t')\n",
        "            except:\n",
        "                # Try to detect delimiter\n",
        "                with open(test_file, 'r') as f:\n",
        "                    first_line = f.readline().strip()\n",
        "                if '\\t' in first_line and ',' in first_line:\n",
        "                    # If both delimiters exist, use the one that gives more splits\n",
        "                    tab_count = first_line.count('\\t')\n",
        "                    comma_count = first_line.count(',')\n",
        "                    delimiter = '\\t' if tab_count > comma_count else ','\n",
        "                elif '\\t' in first_line:\n",
        "                    delimiter = '\\t'\n",
        "                else:\n",
        "                    delimiter = ','\n",
        "\n",
        "                test_df = pd.read_csv(test_file, sep=delimiter)\n",
        "\n",
        "        print(f\"  Test data: {len(test_df)} rows, {len(test_df.columns)} columns\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading files: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Validate column consistency\n",
        "    if set(train_df.columns) != set(test_df.columns):\n",
        "        print(\"Warning: Column mismatch between training and test datasets\")\n",
        "        print(f\"  Training columns: {len(train_df.columns)}\")\n",
        "        print(f\"  Test columns: {len(test_df.columns)}\")\n",
        "        print(\"  Proceeding with intersection of columns...\")\n",
        "        common_columns = list(set(train_df.columns).intersection(set(test_df.columns)))\n",
        "        train_df = train_df[common_columns]\n",
        "        test_df = test_df[common_columns]\n",
        "\n",
        "    # Sample from test dataset\n",
        "    np.random.seed(random_seed)\n",
        "    sample_size = min(k_samples, len(test_df))\n",
        "\n",
        "    if sample_size < k_samples:\n",
        "        print(f\"Warning: Requested {k_samples} samples, but test dataset only has {len(test_df)} rows\")\n",
        "        print(f\"  Using {sample_size} samples instead\")\n",
        "\n",
        "    # Take stratified sample if 'Label' column exists\n",
        "    if 'Label' in test_df.columns:\n",
        "        print(\"Taking stratified sample based on 'Label' column...\")\n",
        "        # Get the class distribution\n",
        "        label_counts = test_df['Label'].value_counts(normalize=True)\n",
        "\n",
        "        # Initialize an empty DataFrame for the samples\n",
        "        test_samples = pd.DataFrame(columns=test_df.columns)\n",
        "\n",
        "        # Sample from each class proportionally\n",
        "        for label, proportion in label_counts.items():\n",
        "            # Calculate how many samples to take from this class\n",
        "            class_sample_size = int(np.ceil(sample_size * proportion))\n",
        "            class_data = test_df[test_df['Label'] == label]\n",
        "\n",
        "            # If there are fewer rows than the requested sample size, take all rows\n",
        "            if len(class_data) <= class_sample_size:\n",
        "                class_samples = class_data\n",
        "            else:\n",
        "                class_samples = class_data.sample(class_sample_size, random_state=random_seed)\n",
        "\n",
        "            # Add to the samples DataFrame\n",
        "            test_samples = pd.concat([test_samples, class_samples])\n",
        "\n",
        "        # If we have more samples than requested, take a random subsample\n",
        "        if len(test_samples) > sample_size:\n",
        "            test_samples = test_samples.sample(sample_size, random_state=random_seed)\n",
        "    else:\n",
        "        # Take a simple random sample if no 'Label' column\n",
        "        print(\"Taking random sample from test dataset...\")\n",
        "        test_samples = test_df.sample(sample_size, random_state=random_seed)\n",
        "\n",
        "    print(f\"Selected {len(test_samples)} samples from test dataset\")\n",
        "\n",
        "    # Add a column to track the source of the data (optional)\n",
        "    if 'data_source' not in train_df.columns and 'data_source' not in test_samples.columns:\n",
        "        train_df['data_source'] = 'original_train'\n",
        "        test_samples['data_source'] = 'test_sample'\n",
        "\n",
        "    # Combine datasets\n",
        "    enhanced_df = pd.concat([train_df, test_samples], ignore_index=True)\n",
        "    print(f\"Enhanced training dataset: {len(enhanced_df)} rows\")\n",
        "\n",
        "    # Shuffle the data\n",
        "    enhanced_df = enhanced_df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
        "\n",
        "    # Save to output file\n",
        "    print(f\"Saving enhanced dataset to {output_file}...\")\n",
        "    enhanced_df.to_csv(output_file, index=False)\n",
        "    print(\"Done!\")\n",
        "\n",
        "    return enhanced_df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Fix and combine Monday-Wednesday files for training\n",
        "    train_files = [\"monday.csv\", \"tuesday.csv\", \"wednesday.csv\"]\n",
        "    train_output = \"fixed_train.csv\"\n",
        "\n",
        "    # Fix and combine Thursday-Friday files for testing\n",
        "    test_files = [\"thursday.csv\", \"friday.csv\"]\n",
        "    test_output = \"fixed_test.csv\"\n",
        "\n",
        "    # Fix and combine all files\n",
        "    print(\"Fixing and combining training files...\")\n",
        "    fixed_train_df = fix_csv_files(train_files, train_output)\n",
        "\n",
        "    print(\"\\nFixing and combining test files...\")\n",
        "    fixed_test_df = fix_csv_files(test_files, test_output)\n",
        "\n",
        "    # Create enhanced training dataset\n",
        "    if fixed_train_df is not None and fixed_test_df is not None:\n",
        "        print(\"\\nCreating enhanced training dataset...\")\n",
        "        enhanced_df = enhance_training_data(\n",
        "            train_output,\n",
        "            test_output,\n",
        "            \"enhanced_train.csv\",\n",
        "            k_samples=1000\n",
        "        )\n",
        "\n",
        "        if enhanced_df is not None and 'Label' in enhanced_df.columns:\n",
        "            print(\"\\nSummary of enhanced dataset:\")\n",
        "            print(f\"Total rows: {len(enhanced_df)}\")\n",
        "            print(f\"Class distribution:\\n{enhanced_df['Label'].value_counts()}\")\n",
        "            if 'data_source' in enhanced_df.columns:\n",
        "                print(f\"Sample source distribution:\\n{enhanced_df['data_source'].value_counts()}\")"
      ],
      "metadata": {
        "id": "HYyA5ClC5WsV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd097e7-6400-4ae6-bb4d-6378f492a32f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fixing and combining training files...\n",
            "Processing monday.csv...\n",
            "  Loaded dataset: 371624 rows, 91 columns\n",
            "Processing tuesday.csv...\n",
            "  Loaded dataset: 322078 rows, 91 columns\n",
            "Processing wednesday.csv...\n",
            "  Loaded dataset: 496641 rows, 91 columns\n",
            "\n",
            "Writing 1190343 rows to fixed_train.csv...\n",
            "Done!\n",
            "\n",
            "Fixing and combining test files...\n",
            "Processing thursday.csv...\n",
            "  Loaded dataset: 362076 rows, 91 columns\n",
            "Processing friday.csv...\n",
            "  Loaded dataset: 547557 rows, 91 columns\n",
            "\n",
            "Writing 909633 rows to fixed_test.csv...\n",
            "Done!\n",
            "\n",
            "Creating enhanced training dataset...\n",
            "Enhancing training data with 1000 samples from test data...\n",
            "Reading training file: fixed_train.csv\n",
            "  Training data: 1190343 rows, 91 columns\n",
            "Reading test file: fixed_test.csv\n",
            "  Test data: 909633 rows, 91 columns\n",
            "Taking stratified sample based on 'Label' column...\n",
            "Selected 1000 samples from test dataset\n",
            "Enhanced training dataset: 1191343 rows\n",
            "Saving enhanced dataset to enhanced_train.csv...\n",
            "Done!\n",
            "\n",
            "Summary of enhanced dataset:\n",
            "Total rows: 1191343\n",
            "Class distribution:\n",
            "Label\n",
            "BENIGN                                    1006478\n",
            "DoS Hulk                                   158468\n",
            "DoS GoldenEye                                7567\n",
            "FTP-Patator                                  3972\n",
            "DoS Slowloris                                3859\n",
            "DoS Slowhttptest - Attempted                 3368\n",
            "SSH-Patator                                  2961\n",
            "DoS Slowloris - Attempted                    1847\n",
            "DoS Slowhttptest                             1740\n",
            "DoS Hulk - Attempted                          581\n",
            "Portscan                                      174\n",
            "DDoS                                          104\n",
            "DoS GoldenEye - Attempted                      80\n",
            "Infiltration - Portscan                        79\n",
            "SSH-Patator - Attempted                        27\n",
            "FTP-Patator - Attempted                        12\n",
            "Heartbleed                                     11\n",
            "Botnet - Attempted                              5\n",
            "Web Attack - Brute Force - Attempted            2\n",
            "Infiltration - Attempted                        1\n",
            "Web Attack - XSS                                1\n",
            "Web Attack - XSS - Attempted                    1\n",
            "Infiltration                                    1\n",
            "Web Attack - Brute Force                        1\n",
            "Web Attack - SQL Injection                      1\n",
            "Botnet                                          1\n",
            "Web Attack - SQL Injection - Attempted          1\n",
            "Name: count, dtype: int64\n",
            "Sample source distribution:\n",
            "data_source\n",
            "original_train    1190343\n",
            "test_sample          1000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import accuracy_score, roc_curve, f1_score, confusion_matrix, roc_auc_score\n",
        "from sklearn.metrics import precision_score, recall_score, classification_report\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"\n",
        "    Load network flow data from file path, attempting multiple delimiters.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # First try tab delimiter\n",
        "        df = pd.read_csv(file_path, delimiter='\\t')\n",
        "\n",
        "        # Check if we ended up with only one column containing all data\n",
        "        if len(df.columns) == 1 and ',' in df.iloc[0, 0]:\n",
        "            print(\"Data loaded as a single column. Trying comma delimiter...\")\n",
        "\n",
        "            # Try with comma delimiter\n",
        "            df = pd.read_csv(file_path, delimiter=',')\n",
        "            print(f\"Loaded dataset with comma delimiter. Shape: {df.shape}\")\n",
        "            return df\n",
        "\n",
        "        print(f\"Loaded dataset with tab delimiter. Shape: {df.shape}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error with standard loading: {e}\")\n",
        "\n",
        "        # Try a manual approach\n",
        "        try:\n",
        "            with open(file_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            # Detect delimiter from first line\n",
        "            first_line = lines[0].strip()\n",
        "            if '\\t' in first_line and ',' in first_line:\n",
        "                # If both tab and comma exist, use the one that gives more splits\n",
        "                tab_count = first_line.count('\\t')\n",
        "                comma_count = first_line.count(',')\n",
        "                delimiter = '\\t' if tab_count > comma_count else ','\n",
        "            elif '\\t' in first_line:\n",
        "                delimiter = '\\t'\n",
        "            elif ',' in first_line:\n",
        "                delimiter = ','\n",
        "            else:\n",
        "                delimiter = ',' # Default to comma\n",
        "\n",
        "            print(f\"Using manual parsing with delimiter: '{delimiter}'\")\n",
        "\n",
        "            # Parse manually\n",
        "            headers = lines[0].strip().split(delimiter)\n",
        "            data = []\n",
        "\n",
        "            for i in range(1, len(lines)):\n",
        "                if lines[i].strip():  # Skip empty lines\n",
        "                    row = lines[i].strip().split(delimiter)\n",
        "                    if len(row) == len(headers):\n",
        "                        data.append(row)\n",
        "                    else:\n",
        "                        print(f\"Warning: Line {i+1} has {len(row)} fields, expected {len(headers)}\")\n",
        "\n",
        "            df = pd.DataFrame(data, columns=headers)\n",
        "            print(f\"Manually loaded dataset with shape: {df.shape}\")\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"Error with manual parsing: {e}\")\n",
        "            raise\n",
        "\n",
        "def preprocess_data(df, scaler=None, fit_scaler=False):\n",
        "    \"\"\"\n",
        "    Preprocess the network flow data according to paper specifications:\n",
        "    - Remove flow identifiers\n",
        "    - Apply min-max normalization\n",
        "    - Convert labels to binary format\n",
        "\n",
        "    Args:\n",
        "        df: The dataframe to preprocess\n",
        "        scaler: An optional pre-fitted scaler (for test data)\n",
        "        fit_scaler: Whether to fit the scaler on this data (for train data)\n",
        "\n",
        "    Returns:\n",
        "        Preprocessed dataframe and the scaler (if fit_scaler=True)\n",
        "    \"\"\"\n",
        "    print(\"\\nPreprocessing data:\")\n",
        "    print(f\"Initial columns: {df.columns.tolist()[:5]}... (total: {len(df.columns)})\")\n",
        "\n",
        "    # Make a copy to avoid modifying the original\n",
        "    df_processed = df.copy()\n",
        "\n",
        "    # Convert label column to binary (0 for BENIGN, 1 for attacks)\n",
        "    if 'Label' in df_processed.columns:\n",
        "        df_processed['Label_Binary'] = df_processed['Label'].apply(lambda x: 0 if str(x).upper() == 'BENIGN' else 1)\n",
        "        # Save the original labels for detailed analysis later\n",
        "        df_processed['Original_Label'] = df_processed['Label']\n",
        "        label_counts = df_processed['Label'].value_counts()\n",
        "        print(f\"Label distribution: {label_counts.to_dict()}\")\n",
        "        binary_counts = df_processed['Label_Binary'].value_counts()\n",
        "        print(f\"Binary label distribution: {binary_counts.to_dict()}\")\n",
        "\n",
        "    # Remove flow identifiers as specified\n",
        "    columns_to_drop = [\n",
        "        'id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Timestamp',\n",
        "        'ICMP Code', 'ICMP Type', 'Total TCP Flow Time', 'Attempted Category', 'Label'\n",
        "    ]\n",
        "\n",
        "    # Drop TTL-based features if they exist\n",
        "    ttl_features = [col for col in df_processed.columns if 'TTL' in col]\n",
        "    columns_to_drop.extend(ttl_features)\n",
        "\n",
        "    # Only drop columns that exist in the dataframe\n",
        "    columns_to_drop = [col for col in columns_to_drop if col in df_processed.columns]\n",
        "    df_cleaned = df_processed.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "    # Convert all columns to numeric, coercing errors to NaN\n",
        "    numeric_cols = []\n",
        "    for col in df_cleaned.columns:\n",
        "        if col != 'Label_Binary' and col != 'Original_Label':\n",
        "            try:\n",
        "                df_cleaned[col] = pd.to_numeric(df_cleaned[col], errors='coerce')\n",
        "                numeric_cols.append(col)\n",
        "            except Exception as e:\n",
        "                print(f\"Error converting column {col} to numeric: {e}\")\n",
        "                df_cleaned = df_cleaned.drop(columns=[col])\n",
        "\n",
        "    # Display info about numeric columns\n",
        "    print(f\"Number of numeric columns after conversion: {len(numeric_cols)}\")\n",
        "    if len(numeric_cols) == 0:\n",
        "        raise ValueError(\"No numeric columns available after preprocessing\")\n",
        "\n",
        "    # Handle NaN values\n",
        "    print(f\"NaN values before handling: {df_cleaned[numeric_cols].isna().sum().sum()}\")\n",
        "\n",
        "    # Replace infinity values with NaN\n",
        "    df_cleaned = df_cleaned.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "    # Check for columns with all NaN values\n",
        "    null_cols = [col for col in numeric_cols if df_cleaned[col].isna().all()]\n",
        "    if null_cols:\n",
        "        print(f\"Dropping columns with all NaN values: {null_cols}\")\n",
        "        df_cleaned = df_cleaned.drop(columns=null_cols)\n",
        "        numeric_cols = [col for col in numeric_cols if col not in null_cols]\n",
        "\n",
        "    # Fill remaining NaN values with column means\n",
        "    for col in numeric_cols:\n",
        "        if df_cleaned[col].isna().any():\n",
        "            col_mean = df_cleaned[col].mean()\n",
        "            df_cleaned[col] = df_cleaned[col].fillna(col_mean)\n",
        "\n",
        "    print(f\"NaN values after handling: {df_cleaned[numeric_cols].isna().sum().sum()}\")\n",
        "\n",
        "    # Verify we have data to work with\n",
        "    if len(numeric_cols) == 0:\n",
        "        raise ValueError(\"No numeric columns available after preprocessing\")\n",
        "\n",
        "    # Apply min-max scaling to all numeric columns\n",
        "    if 'Label_Binary' in df_cleaned.columns:\n",
        "        features = df_cleaned[numeric_cols]\n",
        "        labels = df_cleaned['Label_Binary']\n",
        "        original_labels = df_cleaned.get('Original_Label', None)\n",
        "    else:\n",
        "        features = df_cleaned[numeric_cols]\n",
        "        labels = None\n",
        "        original_labels = None\n",
        "\n",
        "    # Apply scaling\n",
        "    if scaler is None and fit_scaler:\n",
        "        scaler = MinMaxScaler()\n",
        "        scaled_features = scaler.fit_transform(features)\n",
        "    elif scaler is not None:\n",
        "        scaled_features = scaler.transform(features)\n",
        "    else:\n",
        "        raise ValueError(\"Either provide a fitted scaler or set fit_scaler=True\")\n",
        "\n",
        "    # Create a new dataframe with scaled features\n",
        "    scaled_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
        "\n",
        "    # Add back the label columns if they exist\n",
        "    if labels is not None:\n",
        "        scaled_df['Label_Binary'] = labels.values\n",
        "    if original_labels is not None:\n",
        "        scaled_df['Original_Label'] = original_labels.values\n",
        "\n",
        "    print(f\"Preprocessed dataset shape: {scaled_df.shape}\")\n",
        "\n",
        "    if fit_scaler:\n",
        "        return scaled_df, scaler\n",
        "    else:\n",
        "        return scaled_df\n",
        "\n",
        "def evaluate_performance(y_true, y_pred, y_scores, prediction_time, original_labels=None):\n",
        "    \"\"\"Calculate all required performance metrics.\"\"\"\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Calculate AUC - handle case where all predictions are the same class\n",
        "    try:\n",
        "        auc_score = roc_auc_score(y_true, y_scores)\n",
        "    except:\n",
        "        auc_score = 0.5  # Default value when AUC can't be calculated\n",
        "        print(\"Warning: AUC could not be calculated, possibly due to only one class present\")\n",
        "\n",
        "    # Calculate F1 score\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # Calculate precision and recall\n",
        "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Ensure confusion matrix has correct shape for metrics calculation\n",
        "    if cm.shape == (1, 1):  # Only one class predicted\n",
        "        if y_true[0] == 1:  # Only positive class exists\n",
        "            tn, fp, fn, tp = 0, 0, 0, cm[0, 0]\n",
        "        else:  # Only negative class exists\n",
        "            tn, fp, fn, tp = cm[0, 0], 0, 0, 0\n",
        "    elif cm.shape == (2, 1) or cm.shape == (1, 2):  # Handle imbalanced confusion matrix\n",
        "        if cm.size == 2:  # We have two elements\n",
        "            if 1 in y_pred:  # We predicted positive at least once\n",
        "                tn = 0\n",
        "                fp = (y_true == 0).sum() - tn\n",
        "                tp = (y_true == 1).sum() - 0  # All positive samples are TP\n",
        "                fn = 0\n",
        "            else:  # We predicted negative for all\n",
        "                tn = (y_true == 0).sum()\n",
        "                fp = 0\n",
        "                tp = 0\n",
        "                fn = (y_true == 1).sum()\n",
        "    else:  # Normal case\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    # Calculate Detection Rate (DR) and False Alarm Rate (FAR)\n",
        "    detection_rate = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    false_alarm_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "\n",
        "    # Store all metrics\n",
        "    metrics = {\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1,\n",
        "        'AUC': auc_score,\n",
        "        'Detection Rate (DR)': detection_rate,\n",
        "        'False Alarm Rate (FAR)': false_alarm_rate,\n",
        "        'True Negatives': tn,\n",
        "        'False Positives': fp,\n",
        "        'False Negatives': fn,\n",
        "        'True Positives': tp,\n",
        "        'Prediction Time (Î¼s/sample)': prediction_time\n",
        "    }\n",
        "\n",
        "    # Create a detailed analysis of false positives and false negatives\n",
        "    fp_fn_analysis = {}\n",
        "    if original_labels is not None:\n",
        "        # Get indices of false positives and false negatives\n",
        "        fp_indices = np.where((y_true == 0) & (y_pred == 1))[0]\n",
        "        fn_indices = np.where((y_true == 1) & (y_pred == 0))[0]\n",
        "\n",
        "        # Count occurrence of each attack type in false negatives\n",
        "        if len(fn_indices) > 0:\n",
        "            fn_attack_types = original_labels.iloc[fn_indices].value_counts()\n",
        "            fp_fn_analysis['False Negative Types'] = fn_attack_types.to_dict()\n",
        "\n",
        "        # For false positives, they are all benign\n",
        "        fp_fn_analysis['False Positive Count'] = len(fp_indices)\n",
        "\n",
        "    return metrics, fp_fn_analysis\n",
        "\n",
        "def main():\n",
        "    # Load the training data\n",
        "    try:\n",
        "        print(\"Loading training data...\")\n",
        "        train_df = load_data('enhanced_train.csv')\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading training data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Load the test data\n",
        "    try:\n",
        "        print(\"Loading test data...\")\n",
        "        test_df = load_data('fixed_test.csv')\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading test data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Display data summary\n",
        "    print(\"\\nTraining data summary:\")\n",
        "    print(f\"Columns: {train_df.columns.tolist()[:5]} ... (total: {len(train_df.columns)})\")\n",
        "    print(f\"Number of samples: {len(train_df)}\")\n",
        "\n",
        "    print(\"\\nTest data summary:\")\n",
        "    print(f\"Columns: {test_df.columns.tolist()[:5]} ... (total: {len(test_df.columns)})\")\n",
        "    print(f\"Number of samples: {len(test_df)}\")\n",
        "\n",
        "    # Preprocess the training data\n",
        "    try:\n",
        "        print(\"\\nPreprocessing training data...\")\n",
        "        train_processed, scaler = preprocess_data(train_df, fit_scaler=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Error preprocessing training data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Preprocess the test data using the same scaler\n",
        "    try:\n",
        "        print(\"\\nPreprocessing test data...\")\n",
        "        test_processed = preprocess_data(test_df, scaler=scaler, fit_scaler=False)\n",
        "    except Exception as e:\n",
        "        print(f\"Error preprocessing test data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Check if we have the necessary binary label column in both datasets\n",
        "    if 'Label_Binary' not in train_processed.columns:\n",
        "        print(\"No 'Label_Binary' column found in training data after preprocessing. Cannot proceed.\")\n",
        "        return\n",
        "\n",
        "    if 'Label_Binary' not in test_processed.columns:\n",
        "        print(\"No 'Label_Binary' column found in test data after preprocessing. Cannot proceed.\")\n",
        "        return\n",
        "\n",
        "    # Check label distribution in training data\n",
        "    train_label_dist = train_processed['Label_Binary'].value_counts()\n",
        "    print(f\"\\nTraining data label distribution: {train_label_dist.to_dict()}\")\n",
        "\n",
        "    # Check label distribution in test data\n",
        "    test_label_dist = test_processed['Label_Binary'].value_counts()\n",
        "    print(f\"Test data label distribution: {test_label_dist.to_dict()}\")\n",
        "\n",
        "    # Handle case where only one class is present in either dataset\n",
        "    if train_processed['Label_Binary'].nunique() < 2:\n",
        "        print(f\"Warning: Only one class present in training data ({train_processed['Label_Binary'].unique()[0]})\")\n",
        "        print(\"Generating synthetic data for demonstration purposes...\")\n",
        "\n",
        "        # Generate synthetic attack samples\n",
        "        majority_class = train_processed['Label_Binary'].mode()[0]\n",
        "        minority_class = 1 if majority_class == 0 else 0\n",
        "\n",
        "        majority_data = train_processed[train_processed['Label_Binary'] == majority_class]\n",
        "\n",
        "        # Create synthetic minority samples\n",
        "        num_samples = min(int(len(majority_data) * 0.3), 500)\n",
        "        synthetic_samples = majority_data.sample(num_samples, replace=(num_samples > len(majority_data)))\n",
        "\n",
        "        # Add noise to make them different\n",
        "        for col in synthetic_samples.columns:\n",
        "            if col != 'Label_Binary' and col != 'Original_Label':\n",
        "                noise = np.random.normal(0, 0.1, size=len(synthetic_samples))\n",
        "                synthetic_samples[col] = synthetic_samples[col] + noise\n",
        "                synthetic_samples[col] = synthetic_samples[col].clip(0, 1)\n",
        "\n",
        "        # Set minority class\n",
        "        synthetic_samples['Label_Binary'] = minority_class\n",
        "\n",
        "        # Set a dummy original label for synthetic samples\n",
        "        if 'Original_Label' in synthetic_samples.columns:\n",
        "            synthetic_samples['Original_Label'] = 'SYNTHETIC_ATTACK' if minority_class == 1 else 'SYNTHETIC_BENIGN'\n",
        "\n",
        "        # Combine with original data\n",
        "        train_processed = pd.concat([train_processed, synthetic_samples], ignore_index=True)\n",
        "        print(f\"Added {num_samples} synthetic samples of class {minority_class}\")\n",
        "        print(f\"New training label distribution: {train_processed['Label_Binary'].value_counts().to_dict()}\")\n",
        "\n",
        "    # Get the original labels for detailed analysis\n",
        "    original_labels_test = test_processed.get('Original_Label', None)\n",
        "\n",
        "    # Split features and target for training data\n",
        "    X_train = train_processed.drop(['Label_Binary'], axis=1)\n",
        "    if 'Original_Label' in X_train.columns:\n",
        "        X_train = X_train.drop(['Original_Label'], axis=1)\n",
        "    y_train = train_processed['Label_Binary']\n",
        "\n",
        "    # Split features and target for test data\n",
        "    X_test = test_processed.drop(['Label_Binary'], axis=1)\n",
        "    if 'Original_Label' in X_test.columns:\n",
        "        X_test = X_test.drop(['Original_Label'], axis=1)\n",
        "    y_test = test_processed['Label_Binary']\n",
        "\n",
        "    print(f\"\\nTraining features shape: {X_train.shape}\")\n",
        "    print(f\"Training target shape: {y_train.shape}\")\n",
        "    print(f\"Test features shape: {X_test.shape}\")\n",
        "    print(f\"Test target shape: {y_test.shape}\")\n",
        "\n",
        "    # Initialize XGBoost classifier\n",
        "    model = xgb.XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss'\n",
        "    )\n",
        "\n",
        "    # Train the model on the entire training set\n",
        "    print(\"\\nTraining XGBoost model...\")\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Measure prediction time on test set\n",
        "    print(\"\\nEvaluating on test set...\")\n",
        "    start_time = time.time()\n",
        "    y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n",
        "    y_test_pred = model.predict(X_test)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate prediction time per sample in microseconds\n",
        "    test_prediction_time = (end_time - start_time) * 1000000 / len(X_test)\n",
        "\n",
        "    # Calculate final metrics and get detailed false positive/negative analysis\n",
        "    test_metrics, fp_fn_analysis = evaluate_performance(y_test, y_test_pred, y_test_pred_proba,\n",
        "                                                       test_prediction_time, original_labels_test)\n",
        "\n",
        "    # Print test metrics\n",
        "    print(\"\\nTest set performance metrics:\")\n",
        "    for metric_name, metric_value in test_metrics.items():\n",
        "        print(f\"  {metric_name}: {metric_value:.6f}\")\n",
        "\n",
        "    # Print classification report\n",
        "    print(\"\\nDetailed classification report:\")\n",
        "    print(classification_report(y_test, y_test_pred, zero_division=0))\n",
        "\n",
        "    # Print false positive and false negative analysis\n",
        "    print(\"\\nFalse Positive and False Negative Analysis:\")\n",
        "    if 'False Negative Types' in fp_fn_analysis:\n",
        "        print(\"  False Negative breakdown by attack type:\")\n",
        "        for attack_type, count in fp_fn_analysis['False Negative Types'].items():\n",
        "            print(f\"    {attack_type}: {count}\")\n",
        "\n",
        "    print(f\"  Total False Positives: {test_metrics['False Positives']}\")\n",
        "    print(f\"  Total False Negatives: {test_metrics['False Negatives']}\")\n",
        "\n",
        "    try:\n",
        "        # Create directory for plots if it doesn't exist\n",
        "        import os\n",
        "        if not os.path.exists('plots'):\n",
        "            os.makedirs('plots')\n",
        "\n",
        "        # Plot ROC curve\n",
        "        fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.plot(fpr, tpr, label=f'AUC = {test_metrics[\"AUC\"]:.4f}')\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('ROC Curve')\n",
        "        plt.legend(loc='lower right')\n",
        "        plt.grid(True)\n",
        "        plt.savefig('plots/roc_curve.png')\n",
        "        print(\"\\nROC curve saved as 'plots/roc_curve.png'\")\n",
        "        plt.close()\n",
        "\n",
        "        # Plot confusion matrix with percentages\n",
        "        cm = confusion_matrix(y_test, y_test_pred)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.savefig('plots/confusion_matrix.png')\n",
        "        print(\"Confusion matrix saved as 'plots/confusion_matrix.png'\")\n",
        "        plt.close()\n",
        "\n",
        "        # Plot normalized confusion matrix\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues')\n",
        "        plt.xlabel('Predicted')\n",
        "        plt.ylabel('Actual')\n",
        "        plt.title('Normalized Confusion Matrix')\n",
        "        plt.savefig('plots/normalized_confusion_matrix.png')\n",
        "        print(\"Normalized confusion matrix saved as 'plots/normalized_confusion_matrix.png'\")\n",
        "        plt.close()\n",
        "\n",
        "        # Create a more detailed visualization of FP and FN\n",
        "        # Set up the figure with 2 subplots\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
        "\n",
        "        # Left plot: False Negative Distribution by Type (if available)\n",
        "        if 'False Negative Types' in fp_fn_analysis and len(fp_fn_analysis['False Negative Types']) > 0:\n",
        "            fn_types = pd.Series(fp_fn_analysis['False Negative Types'])\n",
        "            fn_types.sort_values(ascending=False).plot(kind='bar', ax=ax1, color='salmon')\n",
        "            ax1.set_title('False Negatives by Attack Type')\n",
        "            ax1.set_ylabel('Count')\n",
        "            ax1.set_xlabel('Attack Type')\n",
        "            ax1.tick_params(axis='x', rotation=90)\n",
        "        else:\n",
        "            ax1.text(0.5, 0.5, 'No False Negatives Available',\n",
        "                    horizontalalignment='center', verticalalignment='center')\n",
        "            ax1.set_title('False Negatives Analysis')\n",
        "\n",
        "        # Right plot: Metrics Comparison\n",
        "        metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1 Score', 'AUC']\n",
        "        values = [test_metrics[metric] for metric in metrics_to_plot]\n",
        "        ax2.bar(metrics_to_plot, values, color='lightblue')\n",
        "        ax2.set_title('Performance Metrics')\n",
        "        ax2.set_ylim(0, 1)\n",
        "        ax2.set_ylabel('Score')\n",
        "        ax2.tick_params(axis='x', rotation=45)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('plots/detailed_performance.png')\n",
        "        print(\"Detailed performance metrics saved as 'plots/detailed_performance.png'\")\n",
        "        plt.close()\n",
        "\n",
        "        # Plot feature importance\n",
        "        plt.figure(figsize=(12, 10))\n",
        "        xgb.plot_importance(model, max_num_features=20)\n",
        "        plt.title('Feature Importance')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('plots/feature_importance.png')\n",
        "        print(\"Feature importance plot saved as 'plots/feature_importance.png'\")\n",
        "        plt.close()\n",
        "\n",
        "        # Generate precision-recall curve\n",
        "        from sklearn.metrics import precision_recall_curve, average_precision_score\n",
        "        precision, recall, _ = precision_recall_curve(y_test, y_test_pred_proba)\n",
        "        avg_precision = average_precision_score(y_test, y_test_pred_proba)\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.plot(recall, precision, label=f'Average Precision = {avg_precision:.4f}')\n",
        "        plt.xlabel('Recall')\n",
        "        plt.ylabel('Precision')\n",
        "        plt.title('Precision-Recall Curve')\n",
        "        plt.legend(loc='best')\n",
        "        plt.grid(True)\n",
        "        plt.savefig('plots/precision_recall_curve.png')\n",
        "        print(\"Precision-recall curve saved as 'plots/precision_recall_curve.png'\")\n",
        "        plt.close()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating plots: {e}\")\n",
        "\n",
        "    print(\"\\nAnalysis complete!\")\n",
        "\n",
        "    # Print a note about synthetic data if it was used\n",
        "    if train_df['Label'].nunique() < 2 or train_processed['Label_Binary'].nunique() < 2:\n",
        "        print(\"\\nNOTE: This analysis used synthetic data for demonstration purposes.\")\n",
        "        print(\"In a real-world scenario, you would need balanced class representation for meaningful results.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "E_DYyDLr5Wp5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dfd5ad2e-b515-47c0-948f-879f08660adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data...\n",
            "Data loaded as a single column. Trying comma delimiter...\n",
            "Loaded dataset with comma delimiter. Shape: (1191343, 92)\n",
            "Loading test data...\n",
            "Data loaded as a single column. Trying comma delimiter...\n",
            "Loaded dataset with comma delimiter. Shape: (909633, 91)\n",
            "\n",
            "Training data summary:\n",
            "Columns: ['id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP'] ... (total: 92)\n",
            "Number of samples: 1191343\n",
            "\n",
            "Test data summary:\n",
            "Columns: ['id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP'] ... (total: 91)\n",
            "Number of samples: 909633\n",
            "\n",
            "Preprocessing training data...\n",
            "\n",
            "Preprocessing data:\n",
            "Initial columns: ['id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP']... (total: 92)\n",
            "Label distribution: {'BENIGN': 1006478, 'DoS Hulk': 158468, 'DoS GoldenEye': 7567, 'FTP-Patator': 3972, 'DoS Slowloris': 3859, 'DoS Slowhttptest - Attempted': 3368, 'SSH-Patator': 2961, 'DoS Slowloris - Attempted': 1847, 'DoS Slowhttptest': 1740, 'DoS Hulk - Attempted': 581, 'Portscan': 174, 'DDoS': 104, 'DoS GoldenEye - Attempted': 80, 'Infiltration - Portscan': 79, 'SSH-Patator - Attempted': 27, 'FTP-Patator - Attempted': 12, 'Heartbleed': 11, 'Botnet - Attempted': 5, 'Web Attack - Brute Force - Attempted': 2, 'Infiltration - Attempted': 1, 'Web Attack - XSS': 1, 'Web Attack - XSS - Attempted': 1, 'Infiltration': 1, 'Web Attack - Brute Force': 1, 'Web Attack - SQL Injection': 1, 'Botnet': 1, 'Web Attack - SQL Injection - Attempted': 1}\n",
            "Binary label distribution: {0: 1006478, 1: 184865}\n",
            "Number of numeric columns after conversion: 80\n",
            "NaN values before handling: 1191343\n",
            "Dropping columns with all NaN values: ['data_source']\n",
            "NaN values after handling: 0\n",
            "Preprocessed dataset shape: (1191343, 81)\n",
            "\n",
            "Preprocessing test data...\n",
            "\n",
            "Preprocessing data:\n",
            "Initial columns: ['id', 'Flow ID', 'Src IP', 'Src Port', 'Dst IP']... (total: 91)\n",
            "Label distribution: {'BENIGN': 576716, 'Portscan': 159066, 'DDoS': 95144, 'Infiltration - Portscan': 71767, 'Botnet - Attempted': 4067, 'Web Attack - Brute Force - Attempted': 1292, 'Botnet': 736, 'Web Attack - XSS - Attempted': 655, 'Web Attack - Brute Force': 73, 'Infiltration - Attempted': 45, 'Infiltration': 36, 'Web Attack - XSS': 18, 'Web Attack - SQL Injection': 13, 'Web Attack - SQL Injection - Attempted': 5}\n",
            "Binary label distribution: {0: 576716, 1: 332917}\n",
            "Number of numeric columns after conversion: 79\n",
            "NaN values before handling: 0\n",
            "NaN values after handling: 0\n",
            "Preprocessed dataset shape: (909633, 81)\n",
            "\n",
            "Training data label distribution: {0: 1006478, 1: 184865}\n",
            "Test data label distribution: {0: 576716, 1: 332917}\n",
            "\n",
            "Training features shape: (1191343, 79)\n",
            "Training target shape: (1191343,)\n",
            "Test features shape: (909633, 79)\n",
            "Test target shape: (909633,)\n",
            "\n",
            "Training XGBoost model...\n",
            "\n",
            "Evaluating on test set...\n",
            "\n",
            "Test set performance metrics:\n",
            "  Accuracy: 0.990542\n",
            "  Precision: 0.999566\n",
            "  Recall: 0.974582\n",
            "  F1 Score: 0.986916\n",
            "  AUC: 0.999512\n",
            "  Detection Rate (DR): 0.974582\n",
            "  False Alarm Rate (FAR): 0.000244\n",
            "  True Negatives: 576575.000000\n",
            "  False Positives: 141.000000\n",
            "  False Negatives: 8462.000000\n",
            "  True Positives: 324455.000000\n",
            "  Prediction Time (Î¼s/sample): 5.526375\n",
            "\n",
            "Detailed classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99    576716\n",
            "           1       1.00      0.97      0.99    332917\n",
            "\n",
            "    accuracy                           0.99    909633\n",
            "   macro avg       0.99      0.99      0.99    909633\n",
            "weighted avg       0.99      0.99      0.99    909633\n",
            "\n",
            "\n",
            "False Positive and False Negative Analysis:\n",
            "  False Negative breakdown by attack type:\n",
            "    Botnet - Attempted: 2769\n",
            "    Infiltration - Portscan: 1606\n",
            "    Web Attack - Brute Force - Attempted: 1292\n",
            "    Portscan: 1151\n",
            "    Botnet: 736\n",
            "    Web Attack - XSS - Attempted: 655\n",
            "    DDoS: 90\n",
            "    Web Attack - Brute Force: 73\n",
            "    Infiltration: 36\n",
            "    Infiltration - Attempted: 20\n",
            "    Web Attack - XSS: 18\n",
            "    Web Attack - SQL Injection: 12\n",
            "    Web Attack - SQL Injection - Attempted: 4\n",
            "  Total False Positives: 141\n",
            "  Total False Negatives: 8462\n",
            "\n",
            "ROC curve saved as 'plots/roc_curve.png'\n",
            "Confusion matrix saved as 'plots/confusion_matrix.png'\n",
            "Normalized confusion matrix saved as 'plots/normalized_confusion_matrix.png'\n",
            "Detailed performance metrics saved as 'plots/detailed_performance.png'\n",
            "Feature importance plot saved as 'plots/feature_importance.png'\n",
            "Precision-recall curve saved as 'plots/precision_recall_curve.png'\n",
            "\n",
            "Analysis complete!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1000 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gjGsjTxO5WnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S930ZnL65Wka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3xMB0V8S5Whu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5C5kI9-F5Wes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AVDRh-FL5WaF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}